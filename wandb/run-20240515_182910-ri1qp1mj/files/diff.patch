diff --git a/.vscode/launch.json b/.vscode/launch.json
index 5bad0c5..9baab0e 100644
--- a/.vscode/launch.json
+++ b/.vscode/launch.json
@@ -19,12 +19,11 @@
             "cwd": "/home/huseyin/fungtion/dannpy_yeniden/DANN_py3",
             "program": "/home/huseyin/fungtion/dannpy_yeniden/DANN_py3/main.py",
             "args": ["-bs", "128", 
-                     "-ll","8",
-                     "-dcms","1","2","4","8",
-                     "-Mss","120","60","80","100",
+                     "-ll","2","3","4","5","6","7","8","9",
+                     "-dcms","1",
+                     "-Mss","240",
                      "-Mt","20",
-                     "-Ns","6000",
-                     "-Nt","6000",
+                     "-NsNt","400","900",
                      "-r","1",
                      "-e","5",
                      "-pn","debugging",
diff --git a/main.py b/main.py
index 7e3440c..efaef9c 100644
--- a/main.py
+++ b/main.py
@@ -29,7 +29,7 @@ def parse_args():
 	parser.add_argument('-mss','--ms_list',type = float, nargs = "+", default = None, help = 'list of ratio of labeled source images')
 	parser.add_argument('-Mss','--Ms_list',type = int, nargs = "+", default = None, help = 'list of total number of labeled source images')
 	parser.add_argument('-Mt','--Mt',type = int, default = 25, help = 'ratio of labeled target images')
-	# parser.add_argument('-mts','--mt_list',type = float, nargs = "+", default = None, help = 'list of ratio of labeled target images')
+	parser.add_argument('-Mts','--Mt_list',type = int, nargs = "+", default = None, help = 'list of labeled target images')
 	# parser.add_argument('-dc_dim','--dc_dim',type = int, default = 100, help = 'dimension of the domain classifier network')
 	# parser.add_argument('-log','--log_wandb',type=bool, default= True, help="whether to log to wandb or not")
 	# parser.add_argument('-l','--layers',type=int, help="number of layers")
@@ -38,6 +38,7 @@ def parse_args():
 	# parser.add_argument('-rn','--run_name',type=str, help="name of the run")
 	# parser.add_argument('-Mts','--Mt_list',type = int, nargs = "+", default = None, help = 'list of number of labeled target images per batch')
 	parser.add_argument('-dcms','--dimchange_multipliers',type = float, nargs = "+", default = None, help = 'list of dimchange multipliers. common for conv and linear layers.')
+	parser.add_argument('-gms','--gammas',type = float, nargs = "+", default = None, help = 'list of gamma weights between source and target class losses. alpha=1 means zero source class loss')
 	parser.add_argument('-beta','--beta',type = float,default = 0.5, help = 'balance parameter between classfication and domain losses. beta =1 means zero contribution from domain loss.')
 	parser.add_argument('-Ns','--Ns',type = int, default = None, help ='the total number of data used in source')
 	parser.add_argument('-Nt','--Nt',type = int, default = None, help ='the total number of data used in target')
@@ -62,14 +63,15 @@ if __name__ == '__main__':
 	beta = args.beta 
 	
 	Mt = args.Mt
+	dcm = 1
+	Nt = args.Nt
+	Ns = args.Ns
 
 	for repeat in range(args.repeats):
-		for NsNt in args.NsNt:
-			Nt = NsNt
-			Ns = NsNt
+		for Mt in args.Mt_list:
 			for layer in args.layers_list:
 				n_epoch = args.n_epoch if not args.adaptive_epochs else int(50*layer)
-				for dcm in args.dimchange_multipliers:
+				for gamma in args.gammas:
 					for Ms in args.Ms_list:
 						# Ms = int(ms*batch_size)
 						manual_seed = random.randint(1, 10000)
@@ -94,13 +96,13 @@ if __name__ == '__main__':
 								#"allow_val_change": True,
 								"config":{"Ms": Ms, 
 										"Mt": Mt, 
-										"layer":layer, 
-										"beta":beta, 
+										"layer":layer,  
 										"dcm":dcm, 
 										"Ns":Ns, 
 										"Nt":Nt,
 										"bs":batch_size,
-										"repeat":repeat+1}
+										"repeat":repeat+1,
+										"gamma":gamma}
 								}
 						
 
@@ -188,8 +190,10 @@ if __name__ == '__main__':
 
 						optimizer = optim.Adam(my_net.parameters(), lr=lr)
 
-						loss_class = torch.nn.NLLLoss(reduction = "sum")
-						loss_domain = torch.nn.NLLLoss(reduction = "sum")
+						# loss_class = torch.nn.NLLLoss(reduction = "sum")
+						# loss_domain = torch.nn.NLLLoss(reduction = "sum")
+						loss_class = torch.nn.NLLLoss(reduction = "mean")
+						loss_domain = torch.nn.NLLLoss(reduction = "mean")
 
 						if cuda:
 							my_net = my_net.cuda()
@@ -289,7 +293,10 @@ if __name__ == '__main__':
 								err_t_label = loss_class(class_output[(batch_size-Mtx):,:], t_label)
 								err_t_domain = loss_domain(domain_output, domain_label)
 
-								err =(1-beta)*(err_t_domain + err_s_domain) + beta*(err_s_label + err_t_label)
+								#err =(1-beta)*(err_t_domain + err_s_domain) + beta*(err_s_label + err_t_label)
+								# err =(6000/NsNt)*(err_t_domain + err_s_domain) + (err_s_label + err_t_label) #summed loss
+								# err = err_t_domain + err_s_domain +       err_s_label +            err_t_label  #average loss
+								err = 0.5 * err_t_domain + 0.5 * err_s_domain + gamma*err_t_label + (1-gamma)* err_s_label  #average, gamma weighted loss
 								err.backward()
 								optimizer.step()
 
diff --git a/wandb/debug-internal.log b/wandb/debug-internal.log
index 2bd7550..2ce8965 120000
--- a/wandb/debug-internal.log
+++ b/wandb/debug-internal.log
@@ -1 +1 @@
-run-20240422_132615-fbv6qzhq/logs/debug-internal.log
\ No newline at end of file
+run-20240515_182910-ri1qp1mj/logs/debug-internal.log
\ No newline at end of file
diff --git a/wandb/debug.log b/wandb/debug.log
index 2563d49..c063889 120000
--- a/wandb/debug.log
+++ b/wandb/debug.log
@@ -1 +1 @@
-run-20240422_132615-fbv6qzhq/logs/debug.log
\ No newline at end of file
+run-20240515_182910-ri1qp1mj/logs/debug.log
\ No newline at end of file
diff --git a/wandb/latest-run b/wandb/latest-run
index b06940e..1f788b6 120000
--- a/wandb/latest-run
+++ b/wandb/latest-run
@@ -1 +1 @@
-run-20240422_132615-fbv6qzhq
\ No newline at end of file
+run-20240515_182910-ri1qp1mj
\ No newline at end of file
